{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\software_3\\\\Generative_models\\\\Text_models\\\\chat_gpt2\\\\SFT_LoRA_QLoRA_RLHF'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current path is changed to\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'d:\\\\software_3\\\\Generative_models\\\\Text_models\\\\chat_gpt2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "%pwd\n",
    "print(f\"The current path is changed to\")\n",
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Finetunning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook implements the supervised funetunning which makes the pretraind model (The model which is trained on large corpus) to be able to responds to the user asked queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from gpt import GPTModel\n",
    "from utils.generate import generate\n",
    "from utils.download_dataset import download_and_load_dataset, partition_data\n",
    "from utils.train import train_model\n",
    "from utils.load_and_save_models import load_model, save_model\n",
    "from utils.token_converter import get_tokenizer, text_to_token_ids, token_ids_to_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    return \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately complates the request.\"\n",
    "        f\"\\n\\n## Instruction:\\n{entry[\"instruction\"]}\"\n",
    "    )\n",
    "    input_text = (\n",
    "        f\"\\n\\n### Input:\\n{entry[\"input\"]}\" if entry[\"input\"] else \" \"\n",
    "\n",
    "    )\n",
    "    return instruction_text + input_text\n",
    "\n",
    "\n",
    "\n",
    "# The custom collate function taked the data batch and makes the instructions and responses inside the batch of the same size.\n",
    "def custom_collate_fn(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    ignore_index=-100,\n",
    "    allowed_max_length=None,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    input_batch, target_batch = zip(*batch)\n",
    "    batch_max_length = max(item.shape[1] for item in input_batch)\n",
    "\n",
    "    padded_inputs = []\n",
    "    padded_targets = []\n",
    "    \n",
    "    for inputs, targets in zip(input_batch, target_batch):\n",
    "        input = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        pad_length = batch_max_length - inputs.shape[1]\n",
    "        if pad_length > 0:\n",
    "            pad_tensor = torch.full((1, pad_length), pad_token_id, device=device)\n",
    "            inputs = torch.cat([inputs, pad_tensor], dim=1)\n",
    "            pad_targets = torch.full((1, pad_length), ignore_index, device=device)\n",
    "            targets = torch.cat([targets, pad_targets], dim=1)\n",
    "\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:, :allowed_max_length]\n",
    "            targets = targets[:, :allowed_max_length]\n",
    "\n",
    "        padded_inputs.append(inputs)\n",
    "        padded_targets.append(targets)\n",
    "\n",
    "    input_tensors = torch.cat(padded_inputs, dim=0)\n",
    "    target_tensors = torch.cat(padded_targets, dim=0)\n",
    "\n",
    "    return input_tensors, target_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstructionDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, tokenizer, device=\"cpu\"):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = device\n",
    "        self.encoded_text = []\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry[\"output\"]}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_text.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        encoded_text = self.encoded_text[index]\n",
    "        # Return input and target tensors with correct shape and device\n",
    "        inputs = torch.tensor(encoded_text[:-1], device=self.device).unsqueeze(0)\n",
    "        targets = torch.tensor(encoded_text[1:], device=self.device).unsqueeze(0)\n",
    "        return inputs, targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloaders(\n",
    "    train_data,\n",
    "    val_data,\n",
    "    test_data,\n",
    "    tokenizer,\n",
    "    batch_size,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    train_dataset = InstructionDataset(train_data, tokenizer,device=device)\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=custom_collate_fn,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "        num_workers=0\n",
    "    )\n",
    "\n",
    "    test_dataset = InstructionDataset(test_data, tokenizer,device=device)\n",
    "    test_dataloader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=custom_collate_fn,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "        num_workers=0\n",
    "    )\n",
    "\n",
    "    val_dataset = InstructionDataset(val_data, tokenizer,device=device)\n",
    "    val_dataloader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=custom_collate_fn,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "        num_workers=0\n",
    "    )\n",
    "\n",
    "    return train_dataloader, test_dataloader, val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_model(\n",
    "                 model,\n",
    "                 train_loader,\n",
    "                 val_loader,\n",
    "                 optimizer,\n",
    "                 device,\n",
    "                 num_epochs,\n",
    "                 tokenizer,\n",
    "                 val_data,\n",
    "                 eval_freqs=5,\n",
    "                 eval_iter=5,\n",
    "                 ):\n",
    "\n",
    "         \n",
    "   \n",
    "    start_time = time.time()\n",
    "    train_losses, val_losses, token_seen = train_model(\n",
    "            model=model,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            optimizer=optimizer,\n",
    "            device=device,\n",
    "            num_epochs=num_epochs,\n",
    "            eval_freq=eval_freqs,\n",
    "            eval_iter=eval_iter,\n",
    "            start_context=format_input(val_data[0]),\n",
    "            tokenizer=tokenizer\n",
    "        )\n",
    "\n",
    "    end_time = time.time()\n",
    "    execution_time_in_minutes = (end_time - start_time) / 60\n",
    "    print(f\"training completed in {execution_time_in_minutes:.2f} minutes.\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetunning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"drop_rate\": 0.0,       # Dropout rate\n",
    "    \"qkv_bias\": True        # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-small (355M)\"\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "gpt = GPTModel(BASE_CONFIG)\n",
    "device = get_device()\n",
    "tokenizer = get_tokenizer()\n",
    "model_name = \"GPT2-355M-pretrained\"\n",
    "\n",
    "model = load_model(model=gpt,\n",
    "                   model_name=model_name,\n",
    "                   device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data length: 935\n",
      "Test data length: 110\n",
      "Validation data length: 55\n"
     ]
    }
   ],
   "source": [
    "data = download_and_load_dataset(\"instruction-data.json\")\n",
    "train_data, test_data, val_data = partition_data(data)\n",
    "train_dataloader, test_dataloader, val_dataloader = dataloaders(train_data, val_data, test_data, tokenizer=tokenizer,batch_size=16)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "num_epochs = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 59/59 [03:52<00:00,  3.94s/it, train_loss=0.635, val_loss=0.854]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 1] Sample Generation:\n",
      "Below is an instruction that describes a task. Write a response that appropriately complates the request.  ## Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'   ### Response: The active sentence is passive.  ### Input: The chef cooked the meal every day.  ### Response: The active sentence is passive.  ### Input: The chef cooked the meal every\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 59/59 [03:33<00:00,  3.61s/it, train_loss=0.446, val_loss=0.752]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 2] Sample Generation:\n",
      "Below is an instruction that describes a task. Write a response that appropriately complates the request.  ## Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'   ### Response: The chef cooked the meal every day.  ### Input: The meal was prepared by the chef.  ### Response: The meal was prepared by the chef.  ### Input: The chef\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 59/59 [03:44<00:00,  3.81s/it, train_loss=0.319, val_loss=0.796]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 3] Sample Generation:\n",
      "Below is an instruction that describes a task. Write a response that appropriately complates the request.  ## Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'   ### Response: The chef cooks the meal every day.  ### Input: The chef cooked the meal every day.  ### Response: The meal was cooked by the chef.  ### Input: The chef\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 59/59 [03:33<00:00,  3.61s/it, train_loss=0.256, val_loss=0.854]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 4] Sample Generation:\n",
      "Below is an instruction that describes a task. Write a response that appropriately complates the request.  ## Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'   ### Response: The chef cooked the meal every day.  ### Input: The meal was cooked by the chef.  ### Response: The meal was cooked by the chef.  ### Response: The chef\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 59/59 [03:24<00:00,  3.46s/it, train_loss=0.234, val_loss=0.805]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 5] Sample Generation:\n",
      "Below is an instruction that describes a task. Write a response that appropriately complates the request.  ## Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'   ### Response: The meal is cooked by the chef every day.  ### Input: The chef cooked the meal every day.  ### Response: The meal is cooked by the chef every day.  ### Input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 59/59 [03:16<00:00,  3.34s/it, train_loss=0.214, val_loss=0.821]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 6] Sample Generation:\n",
      "Below is an instruction that describes a task. Write a response that appropriately complates the request.  ## Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'   ### Response: The chef cooks the meal every day.  ### Input: The chef cooked the meal every day.  ### Response: The meal was cooked by the chef every day.  ### Input: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 59/59 [03:28<00:00,  3.53s/it, train_loss=0.197, val_loss=0.800]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 7] Sample Generation:\n",
      "Below is an instruction that describes a task. Write a response that appropriately complates the request.  ## Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'   ### Response: The chef cooks the meal every day.  ### Input: The meal is prepared by the chef.  ### Response: The meal is prepared by the chef.  ### Response: The chef\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 59/59 [03:18<00:00,  3.36s/it, train_loss=0.180, val_loss=0.926]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 8] Sample Generation:\n",
      "Below is an instruction that describes a task. Write a response that appropriately complates the request.  ## Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'   ### Response: The meal is prepared by the chef.  ### Input: The chef cooks the meal every day.  ### Response: The meal is prepared by the chef.  ### Input: The chef\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 59/59 [03:50<00:00,  3.90s/it, train_loss=0.163, val_loss=0.885]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 9] Sample Generation:\n",
      "Below is an instruction that describes a task. Write a response that appropriately complates the request.  ## Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'   ### Response: The meal every day is cooked by the chef.  ### Input: The chef cooks the meal every day.  ### Response: The meal every day is cooked by the chef.  ### Input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 59/59 [03:15<00:00,  3.32s/it, train_loss=0.155, val_loss=0.885]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 10] Sample Generation:\n",
      "Below is an instruction that describes a task. Write a response that appropriately complates the request.  ## Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'   ### Response: The meal is cooked by the chef.  ### Input: The chef cooks the meal every day.  ### Response: The meal is cooked by the chef.  ### Response: The chef\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 59/59 [03:12<00:00,  3.26s/it, train_loss=0.149, val_loss=0.915]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 11] Sample Generation:\n",
      "Below is an instruction that describes a task. Write a response that appropriately complates the request.  ## Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'   ### Response: The meal is cooked by the chef.  ### Input: The chef cooks the meal every day.  ### Response: The meal is cooked by the chef.  ### Response: The chef\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 59/59 [03:33<00:00,  3.61s/it, train_loss=0.144, val_loss=0.888]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 12] Sample Generation:\n",
      "Below is an instruction that describes a task. Write a response that appropriately complates the request.  ## Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'   ### Response: The meal is cooked by the chef.  ### Input: The chef cooked the meal every day.  ### Response: The meal was cooked by the chef.  ### Response: The chef\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 59/59 [03:27<00:00,  3.51s/it, train_loss=0.143, val_loss=0.907]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 13] Sample Generation:\n",
      "Below is an instruction that describes a task. Write a response that appropriately complates the request.  ## Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'   ### Response: The meal is cooked by the chef.  ### Input: The chef cooks the meal every day.  ### Response: The meal is cooked by the chef.  ### Input: The chef\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 59/59 [04:11<00:00,  4.27s/it, train_loss=0.139, val_loss=0.909]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 14] Sample Generation:\n",
      "Below is an instruction that describes a task. Write a response that appropriately complates the request.  ## Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'   ### Response: The meal is cooked by the chef.  ### Input: The chef cooks the meal every day.  ### Response: The meal is cooked by the chef.  ### Input: The chef\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 59/59 [03:14<00:00,  3.29s/it, train_loss=0.140, val_loss=0.906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 15] Sample Generation:\n",
      "Below is an instruction that describes a task. Write a response that appropriately complates the request.  ## Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'   ### Response: The meal is cooked by the chef.  ### Input: The chef cooks the meal every day.  ### Response: The meal is cooked by the chef.  ### Input: The chef\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 59/59 [03:05<00:00,  3.14s/it, train_loss=0.138, val_loss=0.920]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 16] Sample Generation:\n",
      "Below is an instruction that describes a task. Write a response that appropriately complates the request.  ## Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'   ### Response: The meal is cooked by the chef.  ### Input: The chef cooks the meal every day.  ### Response: The meal is cooked by the chef.  ### Input: The chef\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 59/59 [03:13<00:00,  3.28s/it, train_loss=0.138, val_loss=0.911]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 17] Sample Generation:\n",
      "Below is an instruction that describes a task. Write a response that appropriately complates the request.  ## Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'   ### Response: The meal every day is cooked by the chef.  ### Input: The chef cooks the meal every day.  ### Response: The meal every day is cooked by the chef.  ### Input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 59/59 [03:00<00:00,  3.07s/it, train_loss=0.138, val_loss=0.921]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 18] Sample Generation:\n",
      "Below is an instruction that describes a task. Write a response that appropriately complates the request.  ## Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'   ### Response: The meal every day is cooked by the chef.  ### Input: The chef cooks the meal every day.  ### Response: The meal every day is cooked by the chef.  ### Input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 59/59 [04:00<00:00,  4.07s/it, train_loss=0.138, val_loss=0.923]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 19] Sample Generation:\n",
      "Below is an instruction that describes a task. Write a response that appropriately complates the request.  ## Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'   ### Response: The meal every day is cooked by the chef.  ### Input: The chef cooks the meal every day.  ### Response: The meal every day is cooked by the chef.  ### Input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 59/59 [04:53<00:00,  4.97s/it, train_loss=0.134, val_loss=0.923]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 20] Sample Generation:\n",
      "Below is an instruction that describes a task. Write a response that appropriately complates the request.  ## Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'   ### Response: The meal every day is cooked by the chef.  ### Input: The chef cooks the meal every day.  ### Response: The meal every day is cooked by the chef.  ### Input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 59/59 [03:35<00:00,  3.66s/it, train_loss=0.137, val_loss=0.928]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 21] Sample Generation:\n",
      "Below is an instruction that describes a task. Write a response that appropriately complates the request.  ## Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'   ### Response: The meal every day is cooked by the chef.  ### Input: The chef cooks the meal every day.  ### Response: The meal every day is cooked by the chef.  ### Input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 59/59 [03:32<00:00,  3.61s/it, train_loss=0.135, val_loss=0.929]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 22] Sample Generation:\n",
      "Below is an instruction that describes a task. Write a response that appropriately complates the request.  ## Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'   ### Response: The meal every day is cooked by the chef.  ### Input: The chef cooks the meal every day.  ### Response: The meal every day is cooked by the chef.  ### Input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 59/59 [03:16<00:00,  3.34s/it, train_loss=0.135, val_loss=0.924]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 23] Sample Generation:\n",
      "Below is an instruction that describes a task. Write a response that appropriately complates the request.  ## Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'   ### Response: The meal every day is cooked by the chef.  ### Input: The chef cooks the meal every day.  ### Response: The meal every day is cooked by the chef.  ### Input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 59/59 [03:35<00:00,  3.66s/it, train_loss=0.134, val_loss=0.937]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 24] Sample Generation:\n",
      "Below is an instruction that describes a task. Write a response that appropriately complates the request.  ## Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'   ### Response: The meal every day is cooked by the chef.  ### Input: The chef cooks the meal every day.  ### Response: The meal every day is cooked by the chef.  ### Input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 59/59 [03:22<00:00,  3.42s/it, train_loss=0.131, val_loss=0.930]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 25] Sample Generation:\n",
      "Below is an instruction that describes a task. Write a response that appropriately complates the request.  ## Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'   ### Response: The meal every day is cooked by the chef.  ### Input: The chef cooks the meal every day.  ### Response: The meal every day is cooked by the chef.  ### Input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 59/59 [03:17<00:00,  3.35s/it, train_loss=0.133, val_loss=0.939]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 26] Sample Generation:\n",
      "Below is an instruction that describes a task. Write a response that appropriately complates the request.  ## Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'   ### Response: The meal every day is cooked by the chef.  ### Input: The chef cooks the meal every day.  ### Response: The meal every day is cooked by the chef.  ### Input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 59/59 [03:27<00:00,  3.51s/it, train_loss=0.133, val_loss=0.941]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 27] Sample Generation:\n",
      "Below is an instruction that describes a task. Write a response that appropriately complates the request.  ## Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'   ### Response: The meal every day is cooked by the chef.  ### Input: The chef cooks the meal every day.  ### Response: The meal every day is cooked by the chef.  ### Input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 59/59 [03:24<00:00,  3.47s/it, train_loss=0.131, val_loss=0.937]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 28] Sample Generation:\n",
      "Below is an instruction that describes a task. Write a response that appropriately complates the request.  ## Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'   ### Response: The meal every day is cooked by the chef.  ### Input: The chef cooks the meal every day.  ### Response: The meal every day is cooked by the chef.  ### Input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 59/59 [03:42<00:00,  3.76s/it, train_loss=0.133, val_loss=0.944]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 29] Sample Generation:\n",
      "Below is an instruction that describes a task. Write a response that appropriately complates the request.  ## Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'   ### Response: The meal every day is cooked by the chef.  ### Input: The chef cooks the meal every day.  ### Response: The meal every day is cooked by the chef.  ### Input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 59/59 [03:28<00:00,  3.54s/it, train_loss=0.128, val_loss=0.943]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 30] Sample Generation:\n",
      "Below is an instruction that describes a task. Write a response that appropriately complates the request.  ## Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'   ### Response: The meal every day is cooked by the chef.  ### Input: The chef cooks the meal every day.  ### Response: The meal every day is cooked by the chef.  ### Input\n",
      "Model training has been completed.\n",
      "training completed in 106.55 minutes.\n"
     ]
    }
   ],
   "source": [
    "sft_model = finetune_model(\n",
    "                 model=model,\n",
    "                 train_loader=train_dataloader,\n",
    "                 val_loader=val_dataloader,\n",
    "                 optimizer=optimizer,\n",
    "                 device=device,\n",
    "                 num_epochs=num_epochs,\n",
    "                 tokenizer=tokenizer,\n",
    "                 val_data=val_data,\n",
    "                 eval_freqs=5,\n",
    "                 eval_iter=5,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained model has been saved successfully at d:\\software_3\\Generative_models\\Text_models\\chat_gpt2\\gpt_models\\instruction_finetunned_model.pth\n"
     ]
    }
   ],
   "source": [
    "save_model(sft_model, \"instruct-GPT2-355M-SFT.pth\", optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert 45 kilometers to meters. \n",
      "\n",
      "### Instruction:\n",
      "What is the opposite of 'tall'? \n",
      "\n",
      "### Response:\n",
      "The opposite of 'tall' is '\n"
     ]
    }
   ],
   "source": [
    "text = \"Convert 45 kilometers to meters.\"\n",
    "\n",
    "encoded_text =  text_to_token_ids(text, tokenizer).to(device)\n",
    "\n",
    "idx = encoded_text\n",
    "token_ids = generate(\n",
    "        model=sft_model,\n",
    "        idx=encoded_text,\n",
    "        max_new_tokens=30,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        temperature=0.0,\n",
    "        top_k=None,\n",
    "        eos_id=None\n",
    "    )\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
